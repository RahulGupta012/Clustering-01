{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb8f1bd1-d461-4e8c-a181-da65516a7a9c",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #3498db; padding: 10px; border-radius: 10px; text-align: center;\">\n",
    "    <h1 style=\"color: white;\">Clustering 01</h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bcc509-80e3-4b92-9960-ca1f15899048",
   "metadata": {},
   "source": [
    "# Q1. What are the different types of clustering algorithms, and how do they differ in terms of their approach and underlying assumptions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4a6d28-7ea7-4d84-b904-731da27a45dd",
   "metadata": {},
   "source": [
    "Clustering is basically means to categories the datapoints into certain groups according to there identity. Different types of gruops has been created by the clustering which are represents the different characterstics. These comes under `unsupervised mechine learning algorithem` , which means it has no output at all , these alorithems are made for classified the datapoints into groups of datapoints.There are three type of clustering algorithems are popular :\n",
    "\n",
    "1. K-means Clusetring\n",
    "2. Hierarchical  Clustering\n",
    "3. DBSCAN Clustering\n",
    "\n",
    "`K- means Clusetring`\n",
    "- **approach :** Use centriod method for Dividing the dataset into a predefined number (k) of clusters.\n",
    "- **Assumptions :** It takes the datapoints which are nearest to the centroids.\n",
    "\n",
    "\n",
    "`Hierarchical Clustering`\n",
    "- **approach :** Instead of using centroid method it takes each datapoints as a cluster and then making a another cluster by the previous clusters and so on..\n",
    "- **Assumptions :** Does not consider the centroid method and go to the each datapoints.\n",
    "\n",
    "`DBSACN Clustering`\n",
    "- **approach :** Identifies clusters based on the density of data points.\n",
    "- **Assumptions :** It is robust to outliers as it identify outliers as a different category/point.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32f89fd-1861-4007-9003-dd779a231278",
   "metadata": {},
   "source": [
    "# Q2.What is K-means clustering, and how does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120f118c-ffbb-4ad7-8d66-6c43d1b0ae57",
   "metadata": {},
   "source": [
    "K- means clustering is an unsupervised machine learning algorithem , which is used for grouping the datapoints into certain criterion or basis.K-means clusters are clearly seprated from each other ie..they never be overlaped.It is used to understand the underlying petterns in the dataset.The algorithm is widely used in various fields, such as image segmentation, customer segmentation, and anomaly detection. K-means clustering has been performed in three steps which is reapated untill the perfect clusers are made. These steps are :\n",
    "\n",
    "1. Intilizing some k ---> Centroids\n",
    "2. Points that are nearest to the centroids ---> Group\n",
    "3. Move to centroid ---> Mean\n",
    "\n",
    "\n",
    "- 1. Some k values need to be defined as the number of centriods . For defing such number we used a method called ..elbow method. Which are illusarated in answer 04.\n",
    " \n",
    "- 2. after defining the k value, we calculate the distance of a datapoint to the all centroids by using  Euclidean distance and Manhattan distance. and assign the datapoints to the clusers on the basis of minimumb distance ..it..closest from the cluster.\n",
    " \n",
    "- 3. Recalculate the centroids of the clusters by taking the mean of all data points assigned to each cluster.The new centroids represent the updated center of each cluster.\n",
    " \n",
    " Repeat these all steps till the best possible senario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45551e42-70e3-4354-8d89-99d01cddd8dd",
   "metadata": {},
   "source": [
    "# Q3. What are some advantages and limitations of K-means clustering compared to other clustering techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8ee20c-7d0e-4e20-87cf-508458bf59ef",
   "metadata": {},
   "source": [
    "K-means clustering is a good unsupervised algorithem as it is simple and easy , however there are also some disadvatages of using k-means clustering. Both advanatages and disadvatages are shown below ;\n",
    "\n",
    "`Advantages of K-MEANS Clustering `\n",
    "\n",
    "**Computetional Efficiency :** K-means clustering is preferable for the big data set in spite of other clusterings as Hieracichal clustering. Because it has a a definable value ok K centroid. and it does not go for the squncial processing of all data points as hieracichal clustering.It is simple to use and impliment and designed for high daimentional data as well.\n",
    "\n",
    "**Spherical Clusters:** K-means works well when clusters are spherical and equally sized.By the spherical clusters, distribution of data points is clear and distinct, which simplifies the interpretation of the data.\n",
    "\n",
    "`Disadvantages of K-MEANS Clustering`\n",
    "\n",
    "**Not for Categorical Data :** When it comes to categorical data problem will arises with the k-means clustering as it is only designed for the numerical data or continoues vlaues.\n",
    "\n",
    "**Not robust to Outliers:** K-means is sensitive to outliers,as the DBSCAN Clustering. and their presence can significantly impact cluster assignments.\n",
    "\n",
    "**Sensitive to Initial Centroids:** The algorithm's performance can be sensitive to the initial placement of centroids. Different initializations can lead to different final cluster assignments.\n",
    "\n",
    "**Global Minimum:** K-means aims to find a global minimum for the sum of squared distances, which may not always represent the most meaningful clustering for the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8a588a-8b49-4b6b-adad-dd52021b4dc9",
   "metadata": {},
   "source": [
    "# Q4. How do you determine the optimal number of clusters in K-means clustering, and what are some common methods for doing so?"
   ]
  },
  {
   "attachments": {
    "36fcf5e8-9b75-4be0-baf1-91a433e85d1b.PNG": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPIAAAAjCAYAAACuClcuAAAAAXNSR0IArs4c6QAAAARnQU1BAACx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\ntwf4Pxs3yNq6Ps8FAAAAAElFTkSuQmCC\n"
    }
   },
   "cell_type": "markdown",
   "id": "30d28904-c61a-482d-afcc-ccb7a9102b53",
   "metadata": {},
   "source": [
    "Optimal number of clusters, which we call as k value is very important in the k-means clustering as it is the vary first step to proceed in such a algorithem. It determine the number of centriods to make the clusters of the datapoints. There are some methods ..ie..elbow method, which can be used to determine the k value for this algorithem, which are illusarated ;\n",
    "\n",
    "**Elbow Method :** It is a manual method to determine the value of k for k-means clustering. In this method we draw a (wcss vs proabale k value) graph, which seems like elbow. as it is in descending order because as we incresing the k value , wcss value is decresed and at one point of time it will become continuoues. The point when the k value become continues or stable is the k-value.\n",
    "\n",
    "wcss = within cluster sum of squares\n",
    "\n",
    "![WCSS.PNG](attachment:36fcf5e8-9b75-4be0-baf1-91a433e85d1b.PNG)\n",
    "\n",
    "\n",
    "**Silhouette Score:**\n",
    "The silhouette score measures how similar an object is to its own cluster (cohesion) compared to other clusters (separation).\n",
    "Compute the silhouette score for different values of k.\n",
    "Choose the k that maximizes the silhouette score. A higher silhouette score indicates better-defined clusters.\n",
    "\n",
    "**Hyperperameter Tunning :** By hyperparameter tunning we can also find the best k-value according to sitution of the dataset , Gridsearch cv and randiomize search cv can be used for such opreations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7de48fd-59ff-40b8-8f68-6709352cd413",
   "metadata": {},
   "source": [
    "# Q5. What are some applications of K-means clustering in real-world scenarios, and how has it been used to solve specific problems?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698b9d9c-c9f0-4597-a119-ebf47ce4c23e",
   "metadata": {},
   "source": [
    "K-means clustering is a very importnat unsupervised machine learning algorithem, which is used for many real-world problems. Such as \n",
    "- Customer Segament\n",
    "- Image Segament\n",
    "- Anomaly Detection\n",
    "- Document Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61490514-9a51-4b8e-93be-0a3e38349a36",
   "metadata": {},
   "source": [
    "# Q6. How do you interpret the output of a K-means clustering algorithm, and what insights can you derive from the resulting clusters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d968ec7-3eca-4efa-978c-fddf5bc2236e",
   "metadata": {},
   "source": [
    "The result of K-means clustering can give us a great insights about the data. It helps us to learn the nature and behaviour of the data.By categorising the datapoints we can infer the various classes within the data.\n",
    "\n",
    "- Each centroid tells about the mean of the datapoints. By comparing the the avrages of different clusters, we can find the avrage behaviour of the data.\n",
    "- By comparing the two clusters we can know the weightage of certain kind of behaviour in the data.We can infer about the dominate class of the data.\n",
    "- Lower WCSS values suggest more tightly grouped clusters, indicating better separation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f860906e-a9c0-4246-8526-af2aa24691ce",
   "metadata": {},
   "source": [
    "# Q7. What are some common challenges in implementing K-means clustering, and how can you address them?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f36aef-69d6-46e3-a4c5-fb497705c924",
   "metadata": {},
   "source": [
    "**Outliers :** k-means clustering has a big problem of outliers as it is not rebust to outliers. To solve this problems we can use the techniques ..ie..feature sclaing normalization.\n",
    "\n",
    "**Categorical values :** as we know that k-means clustering is designed for numerical values as it is not compitable for categorical values so we can use encoding techniques for transforming the categorical values into numerical.\n",
    "\n",
    "**Computational Complexity :** computetional complexity can be reduced by the daimensionality reduction techniques."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
